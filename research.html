<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>Research ‚Äî Angkon</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&family=Space+Grotesk:wght@500;600&display=swap"
    rel="stylesheet">

  <!-- CSS -->
  <link rel="stylesheet" href="static/css/variables.css">
  <link rel="stylesheet" href="static/css/base.css">
  <link rel="stylesheet" href="static/css/layout.css">
  <link rel="stylesheet" href="static/css/components.css">
  <link rel="stylesheet" href="static/css/pages/research.css">
</head>

<body class="page-research">

  <!-- HEADER -->
<header class="site-header container">

  <a href="/" class="logo">
    <span id="typewriter"></span>
  </a>

  <button class="hamburger" id="hamburger" aria-label="Toggle navigation">
    ‚ò∞
  </button>

  <nav class="nav" id="nav-menu">
    <a href="index.html">Home</a>
    <a href="education.html">Education</a>
    <a href="research.html" class="active">Research</a>
    <a href="experience.html">Experience</a>
    <a href="awards.html">Awards</a>
    <a href="projects.html">Projects</a>
    <a href="static/cv.pdf" target="_blank">CV</a>
  </nav>

  <button id="theme-toggle">‚óê</button>

</header>


  <!-- MAIN -->
  <main class="container">

    <!-- TITLE -->
    <section class="section">
      <h1>Research</h1>
    </section>

    <!-- INTERESTS -->
    <section class="section">
      <h2>Research Interests</h2>

      <div class="interest-list">
        <span class="interest">Robotics Perception</span>
        <span class="interest">Medical Imaging</span>
        <span class="interest">Deep Learning</span>
        <span class="interest">Machine Learning</span>
        <span class="interest">Audio & Speech Processing</span>
      </div>

      <p class="scholar-link">
        üìö <a href="https://scholar.google.com/citations?user=H3siLB4AAAAJ&hl=en" target="_blank">
          Visit my Google Scholar
        </a>
      </p>
    </section>

    <!-- ========================= -->
    <!-- PUBLISHED CONFERENCES -->
    <!-- ========================= -->
    <details class="section-accordion" open>
      <summary>Published Conference Papers</summary>
      <hr>

      <div class="pub-list">

        <div class="pub-item">

          <h3>
            ‚¶ø A Real-Time Automatic Dengue Breeding Zone Detection and Prevention Scheme Using Autonomous Drone
          </h3>

          <p class="pub-meta">
            <b>A. Deb</b>, S. I. Ahmed, A. Islam, M. Haque, S. A. Fattah, C. Shahnaz <br>
            <i>International Conference on Computer and Information Technology (ICCIT), 2023</i>
          </p>

          <details class="pub-details">
            <summary>Key points & links</summary>
            <ul>
              <li><b>Problem:</b> Identifying mosquito breeding zones at scale</li>
              <li><b>Method:</b> MobileNetV2-enabled aerial vision</li>
              <li><b>Contribution:</b> End-to-end autonomous detection & prevention</li>
              <li><b>Application:</b> Public health & robotics</li>
            </ul>

            <p class="pub-links">
              üîó <a href="https://doi.org/10.1109/ICCIT60459.2023.10441054" target="_blank">DOI</a>
            </p>
          </details>

        </div>
        <div class="pub-item">

          <h3>
            ‚¶ø A Joint Optimization Guided CNN‚ÄìTransformer Model for Robust Sleep Stage Classification from EEG
          </h3>

          <p class="pub-meta">
            <b>A. Deb</b>, C. Shahnaz, M. Saquib <br>
            <i>IEEE Engineering in Medicine and Biology Conference (EMBC), 2025</i>
          </p>

          <details class="pub-details">
            <summary>Key points & links</summary>
            <ul>
              <li><b>Problem:</b> Accurate sleep staging from noisy EEG</li>
              <li><b>Method:</b> CNN + channel-wise transformer fusion</li>
              <li><b>Contribution:</b> Joint optimization strategy</li>
              <li><b>Application:</b> Sleep monitoring & healthcare AI</li>
            </ul>
          </details>

        </div>
        <div class="pub-item">

          <h3>
            ‚¶ø VOIS+: A Video Over Intercom Service with Home Automation Features for Advanced Security and Safety
          </h3>

          <p class="pub-meta">
            <b>A. Deb</b> et al. <br>
            <i>
              IEEE International Conference on Robotics, Automation, Artificial-Intelligence and Internet-of-Things
              (RAAICON), 2024
            </i>
          </p>

          <details class="pub-details">
            <summary>Key points & links</summary>
            <ul>
              <li><b>Problem:</b> Secure and intelligent home intercom systems</li>
              <li><b>Method:</b> Video-over-intercom with IoT-enabled automation</li>
              <li><b>Contribution:</b> Integrated communication, monitoring, and control framework</li>
              <li><b>Application:</b> Smart home security and safety systems</li>
            </ul>

            <p class="pub-links">
              üîó <a href="https://doi.org/10.1109/RAAICON64172.2024.10928380" target="_blank">DOI</a>
            </p>
          </details>

        </div>


        <div class="pub-item">

          <h3>
            ‚¶ø Enhancing Communication for the Deaf and Hard-of-Hearing: A Custom Deep Learning Model-Based Approach for
            Real-Time Sign Language Recognition and Translation
          </h3>

          <p class="pub-meta">
            <b>A. Deb</b>, R. Roy, A. Islam, I. Islam, A. Musabbir, M. S. S. Rian, C. Shahnaz <br>
            <i>IEEE Region 10 Humanitarian Technology Conference (R10-HTC), 2024</i>
          </p>

          <details class="pub-details">
            <summary>Key points & links</summary>
            <ul>
              <li><b>Problem:</b> Real-time sign language recognition in unconstrained environments</li>
              <li><b>Method:</b> Custom deep learning pipeline optimized for latency</li>
              <li><b>Contribution:</b> End-to-end translation framework for accessibility</li>
              <li><b>Application:</b> Assistive communication systems</li>
            </ul>

            <p class="pub-links">
              üîó <a href="https://doi.org/10.1109/R10-HTC59322.2024.10778790" target="_blank">DOI</a>
            </p>
          </details>

        </div>
        <div class="pub-item">

          <h3>
            ‚¶ø DPMAS-Net: A Privacy-Preserving Deep Learning Model for EMG-Based Hand Gesture Recognition
          </h3>

          <p class="pub-meta">
            <b>A. Deb</b>, R. Roy, M. S. S. Rian, A. Islam, C. Shahnaz <br>
            <i>IEEE Region 10 Symposium (TENSYMP), 2024</i>
          </p>

          <details class="pub-details">
            <summary>Key points & links</summary>
            <ul>
              <li><b>Problem:</b> Secure gesture recognition from EMG signals</li>
              <li><b>Method:</b> Time‚Äìfrequency domain feature learning</li>
              <li><b>Contribution:</b> Privacy-preserving model design</li>
              <li><b>Application:</b> Wearable and assistive robotics</li>
            </ul>

            <p class="pub-links">
              üîó <a href="http://dx.doi.org/10.1109/TENSYMP61132.2024.10752112" target="_blank">DOI</a>
            </p>
          </details>

        </div>
        <div class="pub-item">

          <h3>
            ‚¶ø N2N2N: A Clean Data Independent Speech Enhancement Approach with Modified cGAN
          </h3>

          <p class="pub-meta">
            <b>A. Deb</b>, Asaduzzaman, R. Roy, A. Islam, C. Shahnaz, M. Saquib <br>
            <i>IEEE Region 10 Conference (TENCON), 2024</i>
          </p>

          <details class="pub-details">
            <summary>Key points & links</summary>
            <ul>
              <li><b>Problem:</b> Speech enhancement without relying on clean reference data</li>
              <li><b>Method:</b> Modified cGAN with noise-to-noise-to-noise training. Mixing noise intentionally to get
                enhanced speech</li>
              <li><b>Contribution:</b> Clean-data-independent learning strategy</li>
              <li><b>Application:</b> Robust real-world speech enhancement</li>
            </ul>

            <p class="pub-links">
              üîó <a href="https://doi.org/10.1109/TENCON61640.2024.10903013" target="_blank">DOI</a>

            </p>
          </details>


        </div>
        <div class="pub-item">

          <h3>
            ‚¶ø Bio-Markers Presence Detection Using Transfer and Ensemble Learning on Retinal OCT Images
          </h3>

          <p class="pub-meta">
            <b>A. Deb</b>, R. Roy, I. Islam, A. Islam, C. Shahnaz <br>
            <i>International Conference on Electrical Engineering and ICT (ICEEICT), 2024</i>
          </p>

          <details class="pub-details">
            <summary>Key points & links</summary>
            <ul>
              <li><b>Problem:</b> Reliable biomarker detection from OCT scans</li>
              <li><b>Method:</b> Transfer learning with ensemble strategies</li>
              <li><b>Contribution:</b> Improved robustness across patients</li>
              <li><b>Application:</b> Clinical decision support</li>
            </ul>

            <p class="pub-links">
              üîó <a href="https://doi.org/10.1109/ICEEICT62016.2024.10534519" target="_blank">DOI</a>
            </p>
          </details>

        </div>
        <div class="pub-item">

          <h3>
            ‚¶ø WnD-UNET: A Waveform and Discrete Wavelet Coefficient-Based 1D Deep Learning Model for Single-Channel
            Noisy Speech Enhancement
          </h3>

          <p class="pub-meta">
            Asaduzzaman, <b>A. Deb</b>, A. Biswas, R. Roy, A. Islam, C. Shahnaz <br>
            <i>
              International Conference on Computer and Information Technology (ICCIT), 2024
            </i>
          </p>

          <details class="pub-details">
            <summary>Key points & links</summary>
            <ul>
              <li><b>Problem:</b> Enhancing single-channel noisy speech signals</li>
              <li><b>Method:</b> Joint waveform and discrete wavelet coefficient learning</li>
              <li><b>Contribution:</b> Hybrid 1D UNet architecture for robust enhancement</li>
              <li><b>Application:</b> Speech communication in noisy environments</li>
            </ul>

            <p class="pub-links">
              üîó <a href="https://doi.org/10.1109/ICCIT64611.2024.11022373" target="_blank">DOI</a>
            </p>
          </details>

        </div>
        <div class="pub-item">

          <h3>
            ‚¶ø Bidirectional Energy Flow in Vehicle-to-Grid and Grid-to-Vehicle Systems with Solar Integration: A
            Simulink-Based Approach
          </h3>

          <p class="pub-meta">
            K. T. Hasan, N. M. Shaon, <b>A. Deb</b>, S. K. Munia, T. Afrin, A. Islam <br>
            <i>
              International Conference on Electrical and Computer Engineering (ICECE), 2024
            </i>
          </p>

          <details class="pub-details">
            <summary>Key points & links</summary>
            <ul>
              <li><b>Problem:</b> Efficient bidirectional energy exchange between EVs and grid</li>
              <li><b>Method:</b> Simulink-based modeling with solar integration</li>
              <li><b>Contribution:</b> Energy flow optimization under renewable constraints</li>
              <li><b>Application:</b> Smart grid and sustainable energy systems</li>
            </ul>

            <p class="pub-links">
              üîó <a href="https://doi.org/10.1109/ICECE64886.2024.11024690" target="_blank">DOI</a>
            </p>
          </details>

        </div>



        


      </div>
    </details>

    <!-- ========================= -->
    <!-- UNDER REVIEW JOURNALS -->
    <!-- ========================= -->
    <details class="section-accordion">
      <summary>Under Review Journals</summary>
      <hr>

      <div class="pub-list">

              <div class="pub-item">

        <h3>
          ‚¶ø CAR-UNet: A ConvNeXT and Attention Aided Residual UNet-Based Deep Learning Model for Monaural Speech
          Enhancement
        </h3>

        <p class="pub-meta">
          <b>A. Deb</b>, R. Roy, C. Shahnaz, W. P. Zhu, M. O. Ahmed <br>
          <i>Under Review ‚Äî IEEE/ACM Transactions on Audio, Speech and Language Processing</i>
        </p>

        <details class="pub-details">
          <summary class="key-points">Key points</summary>
          <ul>
            <li><b>Problem:</b> Robust monaural speech enhancement in adverse noise conditions</li>
            <li><b>Method:</b> ConvNeXT-based encoder with channel-wise gated attention</li>
            <li><b>Contribution:</b> Residual UNet design optimized in the time‚Äìfrequency domain</li>
            <li><b>Evaluation:</b> Multi-dataset and multi-language benchmarking</li>
          </ul>
        </details>

      </div>
      <div class="pub-item">

        <h3>
          ‚¶ø SLOTH-Net: An STFT-Based Multi-Branch Optimized Transformer Head Network for Sleep Stage Classification from
          EEG
        </h3>

        <p class="pub-meta">
          <b>A. Deb</b>, C. Shahnaz, M. Saquib <br>
          <i>Under Review ‚Äî IEEE Journal of Biomedical and Health Informatics</i>
        </p>

        <details class="pub-details">
          <summary class="key-points">Key points</summary>
          <ul>
            <li><b>Problem:</b> Accurate sleep stage classification from noisy EEG signals</li>
            <li><b>Method:</b> Multi-branch transformer heads on STFT representations</li>
            <li><b>Contribution:</b> Optimized attention fusion across temporal‚Äìspectral features</li>
            <li><b>Application:</b> Clinical sleep monitoring systems</li>
          </ul>
        </details>

      </div>
      <div class="pub-item">

        <h3>
          ‚¶ø pFLOCT: A Personalized Federated Learning Framework for Heterogeneous OCT Data Classification
        </h3>

        <p class="pub-meta">
          <b>A. Deb</b>, R. Roy, A. Islam, C. Shahnaz <br>
          <i>Under Review ‚Äî IEEE Access</i>
        </p>

        <details class="pub-details">
          <summary class="key-points">Key points</summary>
          <ul>
            <li><b>Problem:</b> Privacy-aware medical image classification across institutions</li>
            <li><b>Method:</b> Federated learning with adaptive clustering and weight optimization</li>
            <li><b>Contribution:</b> Personalized model adaptation for heterogeneous OCT datasets</li>
            <li><b>Application:</b> Distributed clinical decision support</li>
          </ul>
        </details>

      </div>
      <div class="pub-item">

        <h3>
          ‚¶ø DecodeMI-Net: A Multi-Perspective Neural Network with Channel-Wise Attention for Motor Imagery EEG Decoding
        </h3>

        <p class="pub-meta">
          <b>A. Deb</b>, C. Shahnaz, S. A. Fattah <br>
          <i>Under Review ‚Äî IEEE Access</i>
        </p>

        <details class="pub-details">
          <summary class="key-points">Key points</summary>
          <ul>
            <li><b>Problem:</b> Robust decoding of motor imagery EEG signals</li>
            <li><b>Method:</b> Multi-perspective feature learning with channel-wise attention</li>
            <li><b>Contribution:</b> Improved subject-invariant decoding performance</li>
            <li><b>Application:</b> Brain‚Äìcomputer interface systems</li>
          </ul>
        </details>

      </div>


      </div>
    </details>

    <!-- ========================= -->
    <!-- PUBLISHED JOURNALS -->
    <!-- ========================= -->
    <details class="section-accordion">
      <summary>Published Journals</summary>
      <hr>

      <p class="empty-note">
        Nothing yet ‚Äî keep me in your prayer üôÇ
      </p>
    </details>

    <!-- ========================= -->
    <!-- ONGOING WORK -->
    <!-- ========================= -->
    <details class="section-accordion">
      <summary>Ongoing Work (Ready to be Submitted)</summary>
      <hr>

      <div class="pub-list">

      <div class="pub-item">

        <h3>
          ‚¶ø CAPRes50-GAN: A Word-Level Sign Language Recognition Approach for Real-Life Scenarios Exploiting GAN-Based
          Classifier
        </h3>

        <p class="pub-meta">
          <b>A. Deb</b>, A. Islam, R. Roy, C. Shahnaz, G. Sharma <br>
          <i>Ready to be Submitted ‚Äî IEEE Transactions on Multimedia</i>
        </p>

        <details class="pub-details">
          <summary class="key-points">Key points</summary>
          <ul>
            <li><b>Problem:</b> Word-level sign language recognition in unconstrained environments</li>
            <li><b>Method:</b> GAN-based feature refinement with ResNet-50 backbone</li>
            <li><b>Contribution:</b> Improved generalization for real-life sign language scenarios</li>
            <li><b>Application:</b> Assistive communication and accessibility technologies with real-time analysis</li>
          </ul>
        </details>

      </div>

      </div>
    </details>

  </main>

  <!-- JS -->
  <script src="static/js/theme.js"></script>
  <script src="static/js/nav.js"></script>


</body>

</html>
